{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"TPU"},"cells":[{"cell_type":"code","source":["!pip install import_ipynb\n","import import_ipynb       #This is a package that allows me to get functions directly from colab notebooks\n","from google.colab import drive\n","drive.mount('/content/drive')\n"],"metadata":{"id":"nV-D6Vrzh4VI"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jRrFwtJ9hj0m","executionInfo":{"status":"ok","timestamp":1665751989827,"user_tz":180,"elapsed":8478,"user":{"displayName":"Marco Tommasini","userId":"11815747515139464141"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"4214e180-5e0d-4219-967f-271bcad488c7"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Fifth year/ClearBox/Diffusion_model_training/MNIST_model\n","importing Jupyter notebook from model.ipynb\n","importing Jupyter notebook from utils.ipynb\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["import os\n","import torch\n","import torch.nn as nn\n","import argparse\n","import numpy as np\n","\n","%cd /content/drive/MyDrive/Fifth year/ClearBox/Diffusion_model_training/MNIST_model\n","#%cd /content/drive/MyDrive/Diffusion_model_training/MNIST_model\n","from model import UNET\n","from utils import sin_time_embeding, beta_schedule\n","#from model_test import UNet_conditional\n","from torchvision.datasets import MNIST\n","from torch.utils.data import DataLoader\n","from torchvision.transforms.functional import pil_to_tensor\n","from torchvision.transforms import ToPILImage\n","import torchvision\n","from tqdm import tqdm\n","import sys\n","from PIL import Image\n","from metrics import FID\n"]},{"cell_type":"code","source":["class basics:\n","  def __init__(self, args, number_noise_steps = 1000, beta_start = 1e-4, beta_end = 0.02, image_size = 64, device = \"cuda\"):\n","    self.number_noise_steps = args.number_noise_steps\n","    self.beta_start = args.beta_start\n","    self.beta_end = args.beta_end\n","    self.image_size = args.image_size\n","    self.device = args.device\n","    self.args = args\n","\n","    schedule = beta_schedule(self.beta_start, self.beta_end, self.number_noise_steps)\n","\n","    if args.noise_schedule == \"linear\":\n","      self.beta = schedule.linear()\n","    elif args.noise_schedule == \"quadratic\":\n","      self.beta = schedule.quadratic()\n","    elif args.noise_schedule == \"sigmoid\":\n","      self.beta = schedule.sigmoid() \n","    elif args.noise_schedule == \"cosine\":\n","      self.beta = schedule.cosine()\n","      \n","    self.beta = self.beta.to(args.device)\n","    self.alpha = 1 - self.beta\n","    self.big_alpha = torch.cumprod(self.alpha, dim = 0)\n","  \n","  \n","  def produce_noise(self, x, time_position):\n","    part1 = torch.sqrt(self.big_alpha[time_position])[:, None, None, None]\n","    part2 = torch.sqrt(1 - self.big_alpha[time_position])[:, None, None, None]\n","    noise = torch.randn_like(x)\n","    return part1 * x + part2 * noise, noise\n","\n","  def sampling_image(self, model, batch_size, label, classifier_scale = 3): #Labels has to have batch size\n","    print(\"Start Sampling\")\n","    model.eval()\n","    x_noise = torch.randn(batch_size, 1, self.image_size, self.image_size)\n","    with torch.no_grad(): \n","      for i in tqdm(reversed(range(1, self.number_noise_steps))):\n","        t = (torch.ones(batch_size) * i).long()\n","        t = t.to(self.args.device)\n","        if i == 0:\n","          z = torch.zeros(x_noise.size())\n","        else:\n","          z = torch.randn_like(x_noise)\n","\n","        alpha_buffer = self.alpha[t][:, None, None, None]\n","        big_alpha_buffer = self.big_alpha[t][:, None, None, None]\n","        beta_buffer = self.beta[t][:, None, None, None]\n","        \n","        t = t.unsqueeze(-1).type(torch.float)\n","        sinusoidal_time_embeding = sin_time_embeding(t).to(self.args.device)\n","\n","        x_noise = x_noise.to(self.args.device)\n","        z = z.to(self.args.device)\n","\n","        pred_classified_noise = model(x_noise, sinusoidal_time_embeding, label)\n","        pred_noise = pred_classified_noise\n","\n","        if classifier_scale > 0:  #The classifier scale is what defines the intensity of the interpolation towards the classified predicited noise\n","          pred_unclassified_noise = model(x_noise, sinusoidal_time_embeding, None)\n","          pred_interpolated_noise = torch.lerp(pred_unclassified_noise, pred_classified_noise,classifier_scale)\n","          pred_noise = pred_interpolated_noise\n","\n","        part2 = ((1 - alpha_buffer)/(torch.sqrt(1 - big_alpha_buffer))) * pred_noise\n","        xtm = ((1/torch.sqrt(alpha_buffer)) * (x_noise - part2)) + torch.sqrt(beta_buffer) * z\n","        x_noise = xtm\n","      x_noise = (x_noise.clamp(-1, 1) + 1) / 2\n","      x_noise = (x_noise * 255).type(torch.uint8)\n","    model.train()\n","    return x_noise\n"],"metadata":{"id":"lGQZ5Z2uBbFC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train(args, model,dataloader, optmizer, loss, model_checkpoint = None):#Need to take it out of the basics object and create args \n","  basic_obj = basics(args, args.number_noise_steps, args.beta_start, args.beta_end, args.image_size, args.device)\n","  \n","  if args.use_checkpoints == \"True\" and model_checkpoint != None:  #Load the checkpoints of the model\n","    print(\"Using checkpoint\")\n","    model.load_state_dict(model_checkpoint['model_state_dict'])\n","    optmizer.load_state_dict(model_checkpoint['optimizer_state_dict'])\n","    epoch = model_checkpoint[\"epoch\"]\n","  else:\n","    epoch = 0\n","\n","  while epoch < args.number_epochs:\n","    print(\"Epoch: \", epoch)\n","    list_losses = []\n","    for i, data in tqdm(enumerate(dataloader)):   #Iterating over the images from the dataloader\n","      optmizer.zero_grad()             #Setting gradient to zero after each iteration\n","      \n","      label = data[1].to(args.device)\n","      x0 = data[0].to(args.device)\n","\n","      t = torch.randint(1, args.number_noise_steps, (args.batch_size, )).to(args.device)  #Getting a vector of time values the size of the bactch\n","      \n","      xt_rand, normal_distribution = basic_obj.produce_noise(x0, t)   #Generaring the noisy image at the specified time stamps from vector \"t\"\n","\n","      xt_rand = xt_rand.to(args.device)\n","      normal_distribution = normal_distribution.to(args.device)\n","\n","      t = t.unsqueeze(-1).type(torch.float)\n","      sinusoidal_time_embeding = sin_time_embeding(t).to(args.device) #This needs to be done because the UNET only accepts the time tensor when it is transformed\n","\n","      if torch.rand(1) < 0.1:\n","        label = None\n","\n","      x_pred = model(xt_rand, sinusoidal_time_embeding, label).to(args.device)    #Predicted images from the UNET by inputing the image and the time without the sinusoidal embeding\n","      \n","      Lsimple = loss(normal_distribution, x_pred).to(args.device)\n","      list_losses.append(Lsimple.item())\n","      Lsimple.backward()\n","      optmizer.step()\n","    epoch += 1\n","   \n","    \n","    #Saving Checkpoint\n","      \n","    EPOCH = epoch\n","    PATH = args.checkpoint_directory + \"/\" + args.noise_schedule + \"_\" + \"DiffusionModel.pt\"       \n","    torch.save({\n","        'epoch': EPOCH,\n","        'model_state_dict': model.state_dict(),\n","        'optimizer_state_dict': optmizer.state_dict(),\n","        'LRSeg': args.learning_rate,\n","        }, PATH)\n","    print(\"checkpoint saved\")\n","    if epoch % 10 == 0:\n","      labels_to_predict = torch.tensor(6).to(args.device)\n","      image_sample = basic_obj.sampling_image(model, 1, labels_to_predict)\n","      image_sample1 = torch.squeeze(image_sample)\n","\n","      trsmr = ToPILImage()\n","      img_pil1 = trsmr(image_sample1)\n","      display(img_pil1)\n","    \n","    print(\"The average loss was: \", np.mean(list_losses))\n","\n"],"metadata":{"id":"efqp_4dHWIdu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def main(params):\n","  parser = argparse.ArgumentParser(description='Diffusion model')\n","\n","  parser.add_argument('--device', type=str, default=\"cuda\", help='Device to run the code on')\n","  parser.add_argument('--use_checkpoints', type=str, default=\"False\", help='Use checkpoints')\n","  parser.add_argument('--emb_dimension', type=int, default=256, help='Number of embeded time dimension')\n","  parser.add_argument('--number_noise_steps', type=int, default=1000, help='Numbe of steps required to noise the image')\n","  parser.add_argument('--beta_start', type=float, default=1e-4, help='First value of beta')\n","  parser.add_argument('--beta_end', type=float, default=0.02, help='Last value of beta')\n","  parser.add_argument('--noise_schedule', type=str, default=\"cosine\", help='How the value of beta will change over time')\n","  parser.add_argument('--image_size', type=int, default=32, help='Size of the squared input image')\n","  parser.add_argument('--batch_size', type=int, default=8, help='Batch size')\n","  parser.add_argument('--number_workers', type=int, default=2, help='Number of workers for the dataloader')\n","  parser.add_argument('--number_steps', type=int, default=200, help='How many iterations steps the model will learn from')\n","  parser.add_argument('--number_epochs', type=int, default=30, help='Number of epochs the model will learn from')\n","  parser.add_argument('--learning_rate', type=float, default=1e-4, help='Initial learning rate of the optmizer')\n","  parser.add_argument('--number_classes', type=int, default=10, help='Number of classes for the classifier')\n","  parser.add_argument('--checkpoint_directory', \\\n","  type=str, default=\"/content/drive/MyDrive/Fifth year/ClearBox/Diffusion_model_training/MNIST_model/checkpoints\", help='')\n","\n","  args = parser.parse_args(params)\n","\n","  #Import the Mninst dataset for training and validation\n","  transforms = torchvision.transforms.Compose([                                           \n","      torchvision.transforms.Resize(80),  # args.image_size + 1/4 *args.image_size          \n","      torchvision.transforms.RandomResizedCrop(args.image_size, scale=(0.8, 1.0)),\n","      torchvision.transforms.ToTensor(), \n","      torchvision.transforms.Normalize(0.5, 0.5)])\n","                                                        \n","  dataset_train = MNIST(\"/content/MNIST_train\", download=True, train=True,transform=transforms)\n","\n","  dataloader_train = DataLoader(dataset_train,args.batch_size)\n","  \n","  args = parser.parse_args(params)\n","\n","  diffusion_model = UNET(args, 1,1,number_classes_input=args.number_classes).to(args.device)\n","\n","  optmizer = torch.optim.Adam(diffusion_model.parameters(), lr=args.learning_rate)\n","\n","  loss_mse = nn.MSELoss()\n","  \n","  #Doing the calculation for the number of iterations\n","  size_iterations = len(dataloader_train.dataset)/args.batch_size\n","  params_update = ['--number_steps', str(int(size_iterations))]\n","  params = params + params_update\n","  args = parser.parse_args(params)\n","\n","  if args.use_checkpoints == \"True\":\n","    model_checkpoint = torch.load(args.checkpoint_directory + \"/\" + args.noise_schedule + \"_\" + \"DiffusionModel.pt\")\n","  else:\n","    model_checkpoint = None\n","  answer = input(\"What action to take: \")\n","\n","  if answer == \"train\":\n","    print(\"Number iterations: \", size_iterations)\n","    train(args, diffusion_model, dataloader_train, optmizer, loss_mse,model_checkpoint)\n","\n","  elif answer == \"sample\":\n","    diffusion = basics(args, args.number_noise_steps, args.beta_start, args.beta_end, args.image_size, args.device)\n","    if model_checkpoint is not None:\n","      diffusion_model.load_state_dict(model_checkpoint['model_state_dict'])\n","    labels_to_predict = torch.tensor(3).to(args.device)\n","    image_sample = diffusion.sampling_image(diffusion_model, 1, labels_to_predict)\n","    image_sample1 = torch.squeeze(image_sample)\n","\n","    trsmr = ToPILImage()\n","    img_pil1 = trsmr(image_sample1)\n","    display(img_pil1)\n","\n","  elif answer == \"test\":\n","    with torch.no_grad():\n","      diffusion = basics(args, args.number_noise_steps, args.beta_start, args.beta_end, args.image_size, args.device)\n","      if model_checkpoint is not None:\n","        diffusion_model.load_state_dict(model_checkpoint['model_state_dict'])\n","\n","      scores = []\n","      fid = FID(\"cuda\")\n","      for i, data in enumerate(dataloader_train):\n","        if i % 2 == 1:\n","          label = data[1].to(args.device)\n","          x_real = data[0].to(args.device)\n","\n","          x_pred = diffusion.sampling_image(diffusion_model,1,label)\n","          \n","\n","\n","          print(\"DEBUG\")\n","          print(x_real.size())\n","          trsmr = ToPILImage()\n","          img_pil1 = trsmr(torch.squeeze(x_pred))\n","          display(img_pil1)\n","          img_pil2 = trsmr(torch.squeeze(x_real))\n","          display(img_pil2)\n","         \n","          \n","          x_pred = torch.tensor(x_pred.cpu().detach().numpy(), dtype=torch.float).to(\"cuda\")\n","          x_real = torch.tensor(x_real.cpu().detach().numpy(), dtype=torch.float).to(\"cuda\")\n","\n","          score = fid.calculate_fid(x_real,x_pred)\n","          scores.append(score)\n","          print(score)\n","      print(scores)\n","    \n","\n"],"metadata":{"id":"IPS4MYihSsj4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["  \n","if __name__ == \"__main__\":  \n","  main([\"--device\", \"cpu\",\n","        \"--batch_size\", \"32\",\n","        \"--checkpoint_directory\", \"/content/drive/MyDrive/Diffusion_model_training/MNIST_model/checkpoints\"])\n","  "],"metadata":{"id":"-6SInI-jPc8q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["  x = torch.zeros(1,1,32, 32).to(\"cpu\")\n","  y = torch.zeros(1,1,32, 32).to(\"cpu\")\n","\n","  fid = FID(\"cpu\", \"/content/drive/MyDrive/Fifth year/ClearBox/Diffusion_model_training/MNIST_model/saved_FID_model/FID.pt\")\n","  score = fid.calculate_fid(x,y)\n","  \n","  print(score)"],"metadata":{"id":"E2X1HyMv1ebS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"IW7KhIaI7yzA","executionInfo":{"status":"error","timestamp":1665751951210,"user_tz":180,"elapsed":254,"user":{"displayName":"Marco Tommasini","userId":"11815747515139464141"}},"colab":{"base_uri":"https://localhost:8080/","height":134},"outputId":"4ba0a7e1-4967-4ee3-9287-b9bb0326c2af"},"execution_count":null,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"ignored","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-9-3fc8763df198>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    del fid()\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m can't delete function call\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"uAtcrDtQjXPB"},"execution_count":null,"outputs":[]}]}