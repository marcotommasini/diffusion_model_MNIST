{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"mount_file_id":"1OEfBaD9WaGEzbUDz-JLrjxbwSz2AXUGZ","authorship_tag":"ABX9TyOjKI9U6gxzW7sJYvt2j2/8"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":307,"metadata":{"id":"p353WW64y1Ge","executionInfo":{"status":"ok","timestamp":1665688973399,"user_tz":180,"elapsed":701,"user":{"displayName":"Marco Tommasini","userId":"11815747515139464141"}}},"outputs":[],"source":["import torch\n","from torch import nn\n","import numpy as np\n","import torchvision\n","from torch.utils.data import DataLoader\n","from torchvision.datasets import MNIST\n","from torch.nn.functional import one_hot\n","from tqdm import tqdm\n","import torch.nn.functional as F"]},{"cell_type":"code","source":["class model_conv(nn.Module):\n","  def __init__(self, input_shape = 32, number_classes = 10, train_switch = \"train\"):\n","    super().__init__()\n","    self.input_shape = input_shape\n","    self.train_switch = train_switch\n","    self.num_classes = number_classes\n","\n","    #(batch, 1 , 32, 32)\n","    self.conv1 = nn.Conv2d(1, 32, kernel_size = 3, padding=1, bias=False)\n","    self.relu1 = nn.ReLU()\n","    self.max_pool1 = nn.MaxPool2d(2)\n","    #(batch, 32, 16, 16)\n","\n","    self.conv2 = nn.Conv2d(32, 64, kernel_size = 3, padding=1, bias=False)\n","    self.relu2 = nn.ReLU()\n","    self.max_pool2 = nn.MaxPool2d(2)\n","    #(batch, 64, 8, 8)\n","\n","    shape = ((self.input_shape/4)**2) * 64\n","\n","    self.dropout = nn.Dropout()\n","    self.linear = nn.Linear(4096, out_features = self.num_classes)\n","    self.softmax = nn.Softmax(dim = 1)\n","\n","  def forward(self, x_input):\n","    x1 = self.conv1(x_input)\n","    x1 = self.relu1(x1)\n","    x1 = self.max_pool1(x1)\n","\n","    x2 = self.conv2(x1)\n","    x2 = self.relu2(x2)\n","    x2 = self.max_pool2(x2)\n","    \n","    x_flat = x2.view(x2.size(0), -1)\n","\n","    x_linear = self.dropout(x_flat)\n","    x_linear = self.linear(x_linear)\n","    x_output = self.softmax(x_linear)\n","\n","    if self.train_switch == \"train\":\n","      return x_output\n","    elif self.train_switch == \"FID\":\n","      return x_flat\n"],"metadata":{"id":"Hpi_aeOVzRg7","executionInfo":{"status":"ok","timestamp":1665688974337,"user_tz":180,"elapsed":15,"user":{"displayName":"Marco Tommasini","userId":"11815747515139464141"}}},"execution_count":308,"outputs":[]},{"cell_type":"code","source":["class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n","        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n","        self.conv2_drop = nn.Dropout2d()\n","        self.fc1 = nn.Linear(500, 50)\n","        self.fc2 = nn.Linear(50, 10)\n","\n","    def forward(self, x):\n","        x1 = F.relu(F.max_pool2d(self.conv1(x), 2))\n","        x1 = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x1)), 2))\n","        x_flatten = x1.view(-1, 500)\n","        x2 = F.relu(self.fc1(x_flatten))\n","        x3 = F.dropout(x2, training=self.training)\n","        x_out = self.fc2(x3)\n","        return F.log_softmax(x_out), x2\n","        "],"metadata":{"id":"8wnhhOMhtL1d","executionInfo":{"status":"ok","timestamp":1665688974338,"user_tz":180,"elapsed":16,"user":{"displayName":"Marco Tommasini","userId":"11815747515139464141"}}},"execution_count":309,"outputs":[]},{"cell_type":"code","source":["def train_model(model, optmizer, loss, dataloader, number_epochs = 10, device = \"cuda\"):\n","  for epoch in range(number_epochs):\n","    losses = []\n","    print(\"Epoch: \", epoch)\n","    for i, data in tqdm(enumerate(dataloader)):\n","      optmizer.zero_grad()\n","\n","      x0 = data[0].to(device)\n","      label = data[1].to(device)\n","\n","      x_pred,_ = model(x0)\n","  \n","      loss_calc = F.nll_loss(x_pred, label)\n","      losses.append(loss_calc.item())\n","      loss_calc.backward()\n","      optmizer.step()\n","    epoch += 1\n","    print(np.mean(losses))\n","    #Saving Checkpoint\n","    \n","    EPOCH = epoch\n","    PATH = \"/content/drive/MyDrive/Fifth year/ClearBox/Diffusion_model_training/MNIST_model/saved_FID_model/\"+ \"FID.pt\"       \n","    torch.save({\n","        'epoch': EPOCH,\n","        'model_state_dict': model.state_dict(),\n","        'optimizer_state_dict': optmizer.state_dict()\n","        }, PATH)\n","    print(\"checkpoint saved\")\n","\n","\n","        \n","\n"],"metadata":{"id":"ic8CMlzl6NrK","executionInfo":{"status":"ok","timestamp":1665688974338,"user_tz":180,"elapsed":15,"user":{"displayName":"Marco Tommasini","userId":"11815747515139464141"}}},"execution_count":310,"outputs":[]},{"cell_type":"code","source":["def main():\n","  transforms = torchvision.transforms.Compose([                                           \n","      torchvision.transforms.Resize(80),         \n","      torchvision.transforms.RandomResizedCrop(32, scale=(0.8, 1.0)),\n","      torchvision.transforms.ToTensor(), \n","      torchvision.transforms.Normalize(0.5, 0.5)])\n","                                                        \n","  dataset_train = MNIST(\"/content/MNIST_train\", download=True, train=True,transform=transforms)\n","  batch_size = 64\n","  number_epochs = 10\n","\n","  dataloader_train = DataLoader(dataset_train, batch_size, drop_last=True)\n","  size_iterations = len(dataloader_train.dataset)/batch_size\n","  device = \"cuda\"\n","\n","  loss = nn.CrossEntropyLoss()\n","\n","  model = Net().to(device)\n","\n","  optmizer = torch.optim.Adam(model.parameters())\n","  size_iterations = len(dataloader_train.dataset)/batch_size\n","  print(size_iterations)\n","  train_model(model, optmizer, loss, dataloader_train)\n","\n"," \n","\n","\n"],"metadata":{"id":"DqgcZve292Al","executionInfo":{"status":"ok","timestamp":1665688974339,"user_tz":180,"elapsed":16,"user":{"displayName":"Marco Tommasini","userId":"11815747515139464141"}}},"execution_count":311,"outputs":[]},{"cell_type":"code","source":["if __name__ == \"__main__\":\n","  main()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GkbP2dox-QIu","executionInfo":{"status":"ok","timestamp":1665689258223,"user_tz":180,"elapsed":283899,"user":{"displayName":"Marco Tommasini","userId":"11815747515139464141"}},"outputId":"261b03ae-b099-45bf-e7e7-fc917cf821c5"},"execution_count":312,"outputs":[{"output_type":"stream","name":"stdout","text":["937.5\n","Epoch:  0\n"]},{"output_type":"stream","name":"stderr","text":["0it [00:00, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n","937it [00:28, 32.61it/s]\n"]},{"output_type":"stream","name":"stdout","text":["0.6249547843188207\n","checkpoint saved\n","Epoch:  1\n"]},{"output_type":"stream","name":"stderr","text":["937it [00:28, 32.92it/s]\n"]},{"output_type":"stream","name":"stdout","text":["0.32555840894770727\n","checkpoint saved\n","Epoch:  2\n"]},{"output_type":"stream","name":"stderr","text":["937it [00:28, 32.87it/s]\n"]},{"output_type":"stream","name":"stdout","text":["0.2776930052568399\n","checkpoint saved\n","Epoch:  3\n"]},{"output_type":"stream","name":"stderr","text":["937it [00:27, 33.56it/s]\n"]},{"output_type":"stream","name":"stdout","text":["0.25204056460140006\n","checkpoint saved\n","Epoch:  4\n"]},{"output_type":"stream","name":"stderr","text":["937it [00:27, 33.84it/s]\n"]},{"output_type":"stream","name":"stdout","text":["0.23403437963409573\n","checkpoint saved\n","Epoch:  5\n"]},{"output_type":"stream","name":"stderr","text":["937it [00:29, 32.14it/s]\n"]},{"output_type":"stream","name":"stdout","text":["0.22108195028729982\n","checkpoint saved\n","Epoch:  6\n"]},{"output_type":"stream","name":"stderr","text":["937it [00:28, 32.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["0.21342595421541144\n","checkpoint saved\n","Epoch:  7\n"]},{"output_type":"stream","name":"stderr","text":["937it [00:28, 33.22it/s]\n"]},{"output_type":"stream","name":"stdout","text":["0.2076955917157161\n","checkpoint saved\n","Epoch:  8\n"]},{"output_type":"stream","name":"stderr","text":["937it [00:28, 32.93it/s]\n"]},{"output_type":"stream","name":"stdout","text":["0.20299529471894848\n","checkpoint saved\n","Epoch:  9\n"]},{"output_type":"stream","name":"stderr","text":["937it [00:28, 33.42it/s]"]},{"output_type":"stream","name":"stdout","text":["0.19719728811573448\n","checkpoint saved\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"5_WazsQMEsCj","executionInfo":{"status":"ok","timestamp":1665689258224,"user_tz":180,"elapsed":32,"user":{"displayName":"Marco Tommasini","userId":"11815747515139464141"}}},"execution_count":312,"outputs":[]}]}